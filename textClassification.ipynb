{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import itertools\n",
    "import sys\n",
    "import random\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "    \"\"\"classify by looking at a site\"\"\"\n",
    "    def __init__(self, training_set):\n",
    "        self.training_set = training_set\n",
    "        self.stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "        self.stemmer = nltk.PorterStemmer()\n",
    "        self.minlength = 7\n",
    "        self.maxlength = 25\n",
    "    def text_process_entry(self, example):\n",
    "        site_text = example[0].lower()\n",
    "        original_tokens = itertools.chain.from_iterable(nltk.word_tokenize(w) for w in nltk.sent_tokenize(site_text))\n",
    "        tokens = original_tokens #+ [' '.join(w) for w in ngrams(original_tokens, 2)]\n",
    "        tokens = [w for w in tokens if not w in self.stopwords]\n",
    "        tokens = [w for w in tokens if self.minlength < len(w) < self.maxlength]\n",
    "        tokens = [self.stemmer.stem(w) for w in tokens]\n",
    "        return (tokens, example[1])\n",
    "    def text_process_all(self, exampleset):\n",
    "        processed_training_set = [self.text_process_entry(i) for i in self.training_set]\n",
    "        processed_training_set = filter(lambda x: len(x[0]) > 0, processed_training_set) # remove empty crawls\n",
    "        processed_texts = [i[0] for i in processed_training_set]\n",
    "        all_words = nltk.FreqDist(itertools.chain.from_iterable(processed_texts))\n",
    "        features_to_test = all_words.keys()[:5000]\n",
    "        self.features_to_test = features_to_test\n",
    "        featuresets = [(self.document_features(d), c) for (d,c) in processed_training_set]\n",
    "        return featuresets\n",
    "    def document_features(self, document):\n",
    "        #document_words = set(document)\n",
    "        features = {}\n",
    "        for word in self.features_to_test:\n",
    "            #features['contains(%s)' % word] = (word in document_words)\n",
    "            features['contains(%s)' % word] = (word in document)\n",
    "            #features['occurrencies(%s)' % word] = document.count(word) \n",
    "            #features['atleast3(%s)' % word] = document.count(word) > 3\n",
    "        return features\n",
    "    def build_classifier(self, featuresets):\n",
    "        random.shuffle(featuresets)\n",
    "        cut_point = len(featuresets) / 5\n",
    "        train_set, test_set = featuresets[cut_point:], featuresets[:cut_point]\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        return (classifier, test_set)\n",
    "    def run(self):\n",
    "        featuresets = self.text_process_all(self.training_set)\n",
    "        classifier, test_set = self.build_classifier(featuresets)\n",
    "        self.classifier = classifier\n",
    "        self.test_classifier(classifier, test_set)\n",
    "    def classify(self, text):\n",
    "        return self.classifier.classify(self.document_features(text))\n",
    "    def test_classifier(self, classifier, test_set):\n",
    "        print nltk.classify.accuracy(classifier, test_set)\n",
    "        classifier.show_most_informative_features(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "       contains(homepag) = False          invest : advert =      1.8 : 1.0\n",
      "       contains(oversea) = False          invest : commis =      1.8 : 1.0\n",
      "         contains(addit) = False          invest : commis =      1.8 : 1.0\n",
      "        contains(normal) = False          invest : commis =      1.8 : 1.0\n",
      "       contains(countri) = False          advert : invest =      1.3 : 1.0\n",
      "       contains(special) = False          advert : invest =      1.3 : 1.0\n",
      "        contains(invest) = False          advert : invest =      1.3 : 1.0\n",
      "       contains(compani) = False          advert : invest =      1.3 : 1.0\n",
      "        contains(intern) = False          advert : invest =      1.3 : 1.0\n",
      "       contains(commiss) = False          invest : a la c =      1.2 : 1.0\n",
      "       contains(impress) = False          invest : a la c =      1.2 : 1.0\n",
      "        contains(exclud) = False          invest : commis =      1.1 : 1.0\n",
      "      contains(criteria) = False          advert : commis =      1.0 : 1.0\n",
      "    contains(correspond) = False          advert : commis =      1.0 : 1.0\n",
      "we are a hedge fund collaborating with many banks in europe -> classified as: investment\n",
      "we charge a fixed fee on top of our client's sales -> classified as: investment\n"
     ]
    }
   ],
   "source": [
    "classes = ('a la carte', 'advertising', 'commission', 'investment', 'pay as you go')\n",
    "\n",
    "training_set = [\n",
    "    ('we are a bank specialized in dealing with IT companies', classes[3]),\n",
    "    ('we sell our product at a fixed cost of 10 pounds', classes[0]),\n",
    "    ('the cost per click is 0.01 dollars but if you get more than 10000 impression the cost will be 0.12', classes[1]),\n",
    "    ('we take a 1% commission on all sales, overseas sales have an additional charge of 12%', classes[2]),\n",
    "    ('we charge a 1% on top of your final price.', classes[2]),\n",
    "    ('we sell our product at 5 pounds, excluding with the variant A which costs an extra of 55 pounds', classes[0]),\n",
    "    ('we sell our product at 6 pounds, excluding with the variant B which costs 45 pounds', classes[0]),\n",
    "    ('our commission is normally between 1% and 2%', classes[2]),\n",
    "    ('impressions on the homepage on sundays are worth 0.01 pounds', classes[1]),\n",
    "    ('we will show impressions only to users that correspond to certain criteria.', classes[1]),\n",
    "    ('we manage an hedge fund and we take care of placing investments on behalf of our clients', classes[3]),\n",
    "    ('we bill only for the amount of api you use. 0.10 per 1000 calls', classes[4]),\n",
    "    ('running a virtual machine will cost you 0.12 pounds per hour', classes[4]),\n",
    "    ('we invest in major hedge funds', classes[3]),\n",
    "    ('we are an international bank, based in all countries of europe', classes[3]),\n",
    "]\n",
    "\n",
    "test_text = \"we are a hedge fund collaborating with many banks in europe\"\n",
    "test_text2 = \"we charge a fixed fee on top of our client's sales\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    classifier = Classifier(training_set)\n",
    "    classifier.run()\n",
    "    print \"%s -> classified as: %s\" % (test_text, classifier.classify(test_text))\n",
    "    print \"%s -> classified as: %s\" % (test_text2, classifier.classify(test_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
